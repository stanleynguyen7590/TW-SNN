
 Run on time: 2021-07-12 11:17:50.924718

 Arguments: 
	 gpu                  : True
	 seed                 : 0
	 dataset              : CIFAR10
	 batch_size           : 64
	 architecture         : VGG16
	 learning_rate        : 0.0001
	 pretrained_ann       : ./trained_models/ann/ann_vgg16_cifar10.pth
	 pretrained_snn       : 
	 en_find_threshold    : False
	 test_only            : True
	 log                  : True
	 epochs               : 2
	 lr_interval          : [1, 1, 1]
	 lr_reduce            : 5
	 timesteps            : 250
	 leak                 : 1.0
	 scaling_factor       : 0.7
	 default_threshold    : 1.0
	 activation           : Linear
	 alpha                : 0.3
	 beta                 : 0.01
	 optimizer            : Adam
	 weight_decay         : 0.0005
	 momentum             : 0.95
	 amsgrad              : True
	 dropout              : 0.3
	 kernel_size          : 3
	 test_acc_every_batch : False
	 train_acc_batches    : 200
	 devices              : 0
 Success: Loaded module.features.0.weight from ./trained_models/ann/ann_vgg16_cifar10.pth
 Success: Loaded module.features.3.weight from ./trained_models/ann/ann_vgg16_cifar10.pth
 Success: Loaded module.features.6.weight from ./trained_models/ann/ann_vgg16_cifar10.pth
 Success: Loaded module.features.9.weight from ./trained_models/ann/ann_vgg16_cifar10.pth
 Success: Loaded module.features.12.weight from ./trained_models/ann/ann_vgg16_cifar10.pth
 Success: Loaded module.features.15.weight from ./trained_models/ann/ann_vgg16_cifar10.pth
 Success: Loaded module.features.18.weight from ./trained_models/ann/ann_vgg16_cifar10.pth
 Success: Loaded module.features.21.weight from ./trained_models/ann/ann_vgg16_cifar10.pth
 Success: Loaded module.features.24.weight from ./trained_models/ann/ann_vgg16_cifar10.pth
 Success: Loaded module.features.27.weight from ./trained_models/ann/ann_vgg16_cifar10.pth
 Success: Loaded module.features.30.weight from ./trained_models/ann/ann_vgg16_cifar10.pth
 Success: Loaded module.features.33.weight from ./trained_models/ann/ann_vgg16_cifar10.pth
 Success: Loaded module.features.36.weight from ./trained_models/ann/ann_vgg16_cifar10.pth
 Success: Loaded module.classifier.0.weight from ./trained_models/ann/ann_vgg16_cifar10.pth
 Success: Loaded module.classifier.3.weight from ./trained_models/ann/ann_vgg16_cifar10.pth
 Success: Loaded module.classifier.6.weight from ./trained_models/ann/ann_vgg16_cifar10.pth
 Info: Accuracy of loaded ANN model: 0.9163
 Info: Enable find threshold: FalseLoad threshold
 Info: Thresholds loaded from trained ANN: [5.936321258544922, 4.038158416748047, 1.5017423629760742, 1.0782102346420288, 0.31738173961639404, 0.9205578565597534, 1.061269760131836, 0.187275230884552, 0.8960564136505127, 3.3482749462127686, 0.5442452430725098, 1.431454062461853, 1.7704054117202759, 1.0336339473724365, 1.6443004608154297]
 DataParallel(
  (module): VGG_SNN_STDB(
    (input_layer): PoissonGenerator()
    (features): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): ReLU(inplace)
      (2): Dropout(p=0.3)
      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): ReLU(inplace)
      (5): AvgPool2d(kernel_size=2, stride=2, padding=0)
      (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): ReLU(inplace)
      (8): Dropout(p=0.3)
      (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (10): ReLU(inplace)
      (11): AvgPool2d(kernel_size=2, stride=2, padding=0)
      (12): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (13): ReLU(inplace)
      (14): Dropout(p=0.3)
      (15): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (16): ReLU(inplace)
      (17): Dropout(p=0.3)
      (18): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (19): ReLU(inplace)
      (20): AvgPool2d(kernel_size=2, stride=2, padding=0)
      (21): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (22): ReLU(inplace)
      (23): Dropout(p=0.3)
      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (25): ReLU(inplace)
      (26): Dropout(p=0.3)
      (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (28): ReLU(inplace)
      (29): AvgPool2d(kernel_size=2, stride=2, padding=0)
      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (31): ReLU(inplace)
      (32): Dropout(p=0.3)
      (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (34): ReLU(inplace)
      (35): Dropout(p=0.3)
      (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (37): ReLU(inplace)
      (38): Dropout(p=0.3)
    )
    (classifier): Sequential(
      (0): Linear(in_features=2048, out_features=4096, bias=False)
      (1): ReLU(inplace)
      (2): Dropout(p=0.5)
      (3): Linear(in_features=4096, out_features=4096, bias=False)
      (4): ReLU(inplace)
      (5): Dropout(p=0.5)
      (6): Linear(in_features=4096, out_features=10, bias=False)
    )
  )
)
 Adam (
Parameter Group 0
    amsgrad: True
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0005
) test_loss: 104.9758, test_acc: 0.9034, best: 0.9034 time: 1:19:08
 Highest accuracy: 0.9034